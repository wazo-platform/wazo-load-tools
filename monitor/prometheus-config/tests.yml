rule_files:
    - alerts.yml

evaluation_interval: 1m

# NOTE:
# - Avoid to use ambiguous short syntax (1x10) for values
#   ex: 1x10 will produce 11 values
# - <metric>[10m] is left-open, i.e. samples with timestamps coinciding with
#   the left boundary of the range are excluded. That's why dummy series must
#   have interval less than 10m

tests:
  - name: when memory firing more than 10m
    interval: 1m
    input_series:
      - series: 'node_memory_MemFree_bytes{instance="localhost"}'
        values: '2+0x10'
      - series: 'node_memory_Buffers_bytes{instance="localhost"}'
        values: '2+0x10'
      - series: 'node_memory_Cached_bytes{instance="localhost"}'
        values: '2+0x10'
      - series: 'node_memory_MemTotal_bytes{instance="localhost"}'
        values: '100+0x10'
    alert_rule_test:
      - eval_time: 10m
        alertname: CriticalRAMUsage
        exp_alerts:
          - exp_labels:
              severity: critical
              instance: localhost
            exp_annotations:
              summary: 'Memory usage has been above 90% for more than 10 minutes'
              description: 'Instance **localhost**'

  - name: when memory firing less than 10m
    interval: 1m
    input_series:
      - series: 'node_memory_MemFree_bytes{instance="localhost"}'
        values: '30+0x8 2 2'
      - series: 'node_memory_Buffers_bytes{instance="localhost"}'
        values: '30+0x8 2 2'
      - series: 'node_memory_Cached_bytes{instance="localhost"}'
        values: '30+0x8 2 2'
      - series: 'node_memory_MemTotal_bytes{instance="localhost"}'
        values: '100+0x10'
    alert_rule_test:
      - eval_time: 10m
        alertname: CriticalRAMUsage
        exp_alerts: []

  - name: when cpu load average firing more than 10m
    interval: 1m
    input_series:
      - series: 'node_cpu_seconds_total{instance="localhost", mode="idle"}'
        values: '0+2x20'
    alert_rule_test:
      - eval_time: 20m
        alertname: CriticalCPULoad
        exp_alerts:
          - exp_labels:
              severity: critical
              instance: localhost
            exp_annotations:
              summary: "CPU load average has been above 96% for more than 10 minutes"
              description: 'Instance **localhost**'

  - name: when cpu load average firing less than 10m
    interval: 1m
    input_series:
      - series: 'node_cpu_seconds_total{instance="localhost", mode="idle"}'
        values: '0+4x20'
    alert_rule_test:
      - eval_time: 20m
        alertname: CriticalCPULoad
        exp_alerts: []

  - name: when memory increase linearly
    interval: 1m
    input_series:
        # 10KiB/s (10*1024) * seconds from interval (60) + 1 (to exceed threshold) = 614401
      - series: 'process_resident_memory_bytes{job="rabbitmq", instance="localhost"}'
        values: '0+614401x31'
      - series: 'namedprocess_namegroup_memory_bytes{groupname="rabbitmq", memtype="resident", instance="localhost"}'
        values: '0+614401x31'
    alert_rule_test:
      - eval_time: 31m
        alertname: MemoryLeak
        exp_alerts:
          - exp_labels:
              severity: warning
              instance: localhost
              groupname: rabbitmq
              memtype: resident
            exp_annotations:
              summary: "Memory usage has increased by 10KiB/s for more than 30 minutes"
              description: "Instance **localhost**, Service rabbitmq, Memory 18.16MiB"
      - eval_time: 31m
        alertname: MemoryLeakFromExporter
        exp_alerts:
          - exp_labels:
              severity: warning
              instance: localhost
              job: rabbitmq
            exp_annotations:
              summary: "Memory usage has increased by 10KiB/s for more than 30 minutes"
              description: "Instance **localhost**, Exporter rabbitmq, Memory 18.16MiB"

  - name: when memory increase by big step
    interval: 1m
    input_series:
      - series: 'process_resident_memory_bytes{job="rabbitmq", instance="localhost"}'
        values: '0 6144010+0x30'
      - series: 'namedprocess_namegroup_memory_bytes{groupname="rabbitmq", memtype="resident", instance="localhost"}'
        values: '0 6144010+0x30'
    alert_rule_test:
      - eval_time: 1m
        alertname: MemoryLeak
        exp_alerts: []
      - eval_time: 31m
        alertname: MemoryLeak
        exp_alerts: []
      - eval_time: 1m
        alertname: MemoryLeakFromExporter
        exp_alerts: []
      - eval_time: 31m
        alertname: MemoryLeakFromExporter
        exp_alerts: []

  - name: when memory increase by spike
    interval: 1m
    input_series:
      - series: 'process_resident_memory_bytes{job="rabbitmq", instance="localhost"}'
        values: '0 6144010 0+0x29 '
      - series: 'namedprocess_namegroup_memory_bytes{groupname="rabbitmq", memtype="resident", instance="localhost"}'
        values: '0 6144010 0+0x29'
    alert_rule_test:
      - eval_time: 1m
        alertname: MemoryLeak
        exp_alerts: []
      - eval_time: 31m
        alertname: MemoryLeak
        exp_alerts: []
      - eval_time: 1m
        alertname: MemoryLeakFromExporter
        exp_alerts: []
      - eval_time: 31m
        alertname: MemoryLeakFromExporter
        exp_alerts: []

  - name: when memory decrease linearly
    interval: 1m
    input_series:
      # to have value 0 after 31 min: 614401 * 31 = 19046431
      - series: 'process_resident_memory_bytes{job="rabbitmq", instance="localhost"}'
        values: '19046431-614401x31'
      - series: 'namedprocess_namegroup_memory_bytes{groupname="rabbitmq", memtype="resident", instance="localhost"}'
        values: '19046431-614401x31'
    alert_rule_test:
      - eval_time: 31m
        alertname: MemoryLeak
        exp_alerts: []
      - eval_time: 31m
        alertname: MemoryLeakFromExporter
        exp_alerts: []

  - name: simultaneous calls
    interval: 1m
    input_series:
      - series: 'asterisk_calls_count{instance="localhost"}'
        values: '0+0x9 42+0x9'
    alert_rule_test:
      - eval_time: 10m
        alertname: AsteriskSimultCalls
        exp_alerts: []
      - eval_time: 20m
        alertname: AsteriskSimultCalls
        exp_alerts:
          - exp_labels:
              severity: warning
              instance: localhost
            exp_annotations:
              summary: 'Simultaneous calls are higher than expected'
              description: 'Instance **localhost**, Calls: 42 > 35'

  - name: total calls
    interval: 1m
    input_series:
      - series: 'asterisk_calls_sum{instance="localhost"}'
        values: '0+1x10 10+0x9'
    alert_rule_test:
      - eval_time: 10m
        alertname: AsteriskTotalCalls
        exp_alerts: []
      - eval_time: 20m
        alertname: AsteriskTotalCalls
        exp_alerts:
          - exp_labels:
              severity: warning
              instance: localhost
            exp_annotations:
              summary: 'Total calls are not increasing'
              description: 'Instance **localhost**'

  - name: total calls when reset
    interval: 1m
    input_series:
      - series: 'asterisk_calls_sum{instance="localhost"}'
        values: '0+1x10 0 0 0+1x7'
    alert_rule_test:
      - eval_time: 20m
        alertname: AsteriskTotalCalls
        exp_alerts: []

  - name: postgres connections
    interval: 1m
    input_series:
      - series: 'pg_stat_activity_count{instance="localhost"}'
        values: '50+0x9 91+0x10'
      - series: 'pg_settings_max_connections{instance="localhost"}'
        values: '100+0x19'
    alert_rule_test:
      - eval_time: 10m
        alertname: PGConnectionUsage
        exp_alerts: []
      - eval_time: 20m
        alertname: PGConnectionUsage
        exp_alerts:
          - exp_labels:
              severity: critical
              instance: localhost
            exp_annotations:
              summary: 'PostgreSQL connections usage has been above 90% for more than 10 minutes'
              description: 'Instance **localhost**'

  - name: asterisk file descriptors
    interval: 1m
    input_series:
      - series: 'namedprocess_namegroup_open_filedesc{groupname="asterisk", instance="localhost"}'
        values: '8000+0x4'
    alert_rule_test:
      - eval_time: 5m
        alertname: AsteriskFileDescriptors
        exp_alerts:
          - exp_labels:
              severity: warning
              instance: localhost
              groupname: asterisk
            exp_annotations:
              summary: "Asterisk file descriptors count has been above 90% for more than 5 minutes"
              description: "Instance **localhost**, File Descriptors: 8000"
